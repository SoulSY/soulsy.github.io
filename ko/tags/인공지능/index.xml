<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>인공지능 on SamTech</title>
    <link>https://soulsy.github.io/ko/tags/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/</link>
    <description>Recent content in 인공지능 on SamTech</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko</language>
    <lastBuildDate>Sat, 22 Jul 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://soulsy.github.io/ko/tags/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>순환 신경망 (Recurrent Neural Networks, RNN)</title>
      <link>https://soulsy.github.io/ko/knowledge/tensorflow/recurrent_neural_networks/</link>
      <pubDate>Sat, 22 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>https://soulsy.github.io/ko/knowledge/tensorflow/recurrent_neural_networks/</guid>
      <description>순환 신경망 (Recurrent Neural Networks, RNN) 순환 신경망(Recurrent Neural Network, RNN)은 텍스트, 유전자, 필기 또는 음성과 같은 시퀀스 데이터의 패턴을 인식하도록 설계된 인공 신경망의 한 종류입니다. 기존의 신경망과 달리 RNN에는 루프가 있어 시퀀스의 한 단계에서 다음 단계로 정보를 전달할 수 있습니다.
순환 신경망의 특징 RNN은 숨겨진 상태를 사용해 이전의 입력을 &amp;ldquo;기억&amp;quot;하는 능력으로 알려져 있으며, 이는 시퀀스 데이터를 다루는 작업에 매우 효과적입니다. RNN의 주요 특징은 다음과 같습니다:
순차적 처리: 다른 유형의 신경망이 각 입력을 독립적으로 처리하는 반면, RNN은 입력을 순차적으로 처리합니다.</description>
    </item>
    
    <item>
      <title>Convolutional Neural Networks (CNN)</title>
      <link>https://soulsy.github.io/ko/knowledge/tensorflow/convolutional_neural_networks/</link>
      <pubDate>Tue, 18 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>https://soulsy.github.io/ko/knowledge/tensorflow/convolutional_neural_networks/</guid>
      <description>Convolutional Neural Networks (CNN) Convolutional Neural Networks(CNN)은 이미지와 같이 격자 형태의 구조를 가진 데이터를 처리하는데 특히 뛰어난 성능을 보이는 심층 신경망입니다. CNN은 데이터 내의 공간적 상관관계를 이용하여 일련의 필터를 적용함으로써 데이터의 계층적 표현을 생성하며, 이로 인해 이미지 인식 및 다른 컴퓨터 비전 작업에 매우 효율적입니다.
CNN의 특성 Convolutional Layer: CNN의 주요 구성 요소로, 입력 데이터에 Convolutional 연산을 수행합니다. 이러한 계층은 데이터에서 저차원 특성을 추출하는 일련의 필터를 적용합니다. Pooling Layers: Convolutional 계층 다음에 자주 사용되며, Convolutional된 특성의 공간적 크기를 줄여 네트워크의 연산 부하를 감소시킵니다.</description>
    </item>
    
    <item>
      <title>페이스북, 자사 인공지능 기술 Llama 2 Open Source로 제공</title>
      <link>https://soulsy.github.io/ko/news/010/</link>
      <pubDate>Tue, 18 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>https://soulsy.github.io/ko/news/010/</guid>
      <description>페이스북, 자사 인공지능 기술 Llama 2 Open Source로 제공 출처: Washington Post - 기사 링크 by Gerrit De Vynck, Naomi Nix
페이스북의 소유사인 메타가 혁신적인 인공지능 기술인 Llama 2를 연구 및 제품 개발을 위해 무료로 공개합니다. 이 &amp;ldquo;오픈 소스&amp;rdquo; 접근 방식은 인공지능 분야에서의 경쟁을 촉진하고 동시에 잠재적인 악용 가능성에 대한 우려를 불러일으킵니다.
Llama 2는 수많은 인터넷 자료를 기반으로 훈련된 복잡한 알고리즘으로, 메타에서 직접 다운로드하거나 Microsoft, Amazon, AI 스타트업 Hugging Face와 같은 클라우드 공급업체를 통해 무료로 이용할 수 있습니다.</description>
    </item>
    
    <item>
      <title>트랜스포머 모델</title>
      <link>https://soulsy.github.io/ko/knowledge/tensorflow/transformer_models/</link>
      <pubDate>Sun, 16 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>https://soulsy.github.io/ko/knowledge/tensorflow/transformer_models/</guid>
      <description>트랜스포머 모델 (Transformer Models) 트랜스포머 모델은 연속 데이터를 처리하는 새로운 방법론을 도입함으로써 자연어 처리(NLP) 분야에 혁명을 일으켰습니다. 2017년 Vaswani 등이 &amp;ldquo;Attention is All You Need&amp;rdquo; 라는 논문에서 개발한 이 구조는 자기 주목(self-attention) 메커니즘에 크게 의존하여 문장의 단어 중요도를 가중치로 부여하고, 이를 통해 모델이 문맥을 더욱 잘 이해하게 합니다.
트랜스포머 모델의 특징 RNNs와 LSTMs 같은 이전의 연속 데이터 처리 모델들이 데이터를 순차적으로 처리하는 반면, 트랜스포머는 모든 시퀀스 입력을 동시에 처리합니다. 이로 인해 트랜스포머는 연속 데이터에서 장거리 의존성을 더 효과적으로 처리할 수 있습니다.</description>
    </item>
    
  </channel>
</rss>