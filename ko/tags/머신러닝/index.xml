<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>머신러닝 on SamTech</title>
    <link>https://soulsy.github.io/ko/tags/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/</link>
    <description>Recent content in 머신러닝 on SamTech</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko</language>
    <lastBuildDate>Tue, 18 Jul 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://soulsy.github.io/ko/tags/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Convolutional Neural Networks (CNN)</title>
      <link>https://soulsy.github.io/ko/knowledge/tensorflow/convolutional_neural_networks/</link>
      <pubDate>Tue, 18 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>https://soulsy.github.io/ko/knowledge/tensorflow/convolutional_neural_networks/</guid>
      <description>Convolutional Neural Networks (CNN) Convolutional Neural Networks(CNN)은 이미지와 같이 격자 형태의 구조를 가진 데이터를 처리하는데 특히 뛰어난 성능을 보이는 심층 신경망입니다. CNN은 데이터 내의 공간적 상관관계를 이용하여 일련의 필터를 적용함으로써 데이터의 계층적 표현을 생성하며, 이로 인해 이미지 인식 및 다른 컴퓨터 비전 작업에 매우 효율적입니다.
CNN의 특성 Convolutional Layer: CNN의 주요 구성 요소로, 입력 데이터에 Convolutional 연산을 수행합니다. 이러한 계층은 데이터에서 저차원 특성을 추출하는 일련의 필터를 적용합니다. Pooling Layers: Convolutional 계층 다음에 자주 사용되며, Convolutional된 특성의 공간적 크기를 줄여 네트워크의 연산 부하를 감소시킵니다.</description>
    </item>
    
    <item>
      <title>트랜스포머 모델</title>
      <link>https://soulsy.github.io/ko/knowledge/tensorflow/transformer_models/</link>
      <pubDate>Sun, 16 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>https://soulsy.github.io/ko/knowledge/tensorflow/transformer_models/</guid>
      <description>트랜스포머 모델 (Transformer Models) 트랜스포머 모델은 연속 데이터를 처리하는 새로운 방법론을 도입함으로써 자연어 처리(NLP) 분야에 혁명을 일으켰습니다. 2017년 Vaswani 등이 &amp;ldquo;Attention is All You Need&amp;rdquo; 라는 논문에서 개발한 이 구조는 자기 주목(self-attention) 메커니즘에 크게 의존하여 문장의 단어 중요도를 가중치로 부여하고, 이를 통해 모델이 문맥을 더욱 잘 이해하게 합니다.
트랜스포머 모델의 특징 RNNs와 LSTMs 같은 이전의 연속 데이터 처리 모델들이 데이터를 순차적으로 처리하는 반면, 트랜스포머는 모든 시퀀스 입력을 동시에 처리합니다. 이로 인해 트랜스포머는 연속 데이터에서 장거리 의존성을 더 효과적으로 처리할 수 있습니다.</description>
    </item>
    
  </channel>
</rss>